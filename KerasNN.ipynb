{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating/Building VictoryNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras as ks\n",
    "from keras.callbacks import TensorBoard\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the file and splitting off the target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"indexByMatch_batchUdacity_205_CLEANED_NORM.csv\", index_col=\"Unnamed: 0\")\n",
    "labels = df[\"alphaVictory\"]\n",
    "df.drop(\"alphaVictory\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we take the data from Pandas into Numpy so that our NN can read it easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = df.as_matrix(columns=df.columns[:])\n",
    "label = labels.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the Shape of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124236, 204)\n",
      "(124236,)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into: \n",
    "\n",
    "70% Training\n",
    "\n",
    "20% Testing\n",
    "\n",
    "10% Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size = 0.3, random_state=444)\n",
    "\n",
    "X_TEST, X_VALID, y_TEST, y_VALID = train_test_split(X_test, y_test, test_size = 0.33, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86965, 204)\n",
      "(86965,)\n",
      "(24971, 204)\n",
      "(24971,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_TEST.shape)\n",
    "print(y_TEST.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Setting up the file to hold our learning curves using the Tensorflow backend of Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tbCallBack = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Building our network. This was done using Huang et al's equations. They are equations 1, 2, and 3 in this paper: \n",
    "\n",
    "http://dstath.users.uth.gr/papers/IJRS2009_Stathakis.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(511, activation='relu', input_dim=204))\n",
    "model.add(Dense(170, activation='relu', input_dim=511))\n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adagrad',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the Network and using Validation data to double check the learning process and prevent overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 86965 samples, validate on 12300 samples\n",
      "Epoch 1/10\n",
      "86965/86965 [==============================] - 3s - loss: 0.2036 - acc: 0.9160 - val_loss: 0.1715 - val_acc: 0.9292\n",
      "Epoch 2/10\n",
      "86965/86965 [==============================] - 2s - loss: 0.1721 - acc: 0.9280 - val_loss: 0.1739 - val_acc: 0.9272\n",
      "Epoch 3/10\n",
      "86965/86965 [==============================] - 2s - loss: 0.1551 - acc: 0.9359 - val_loss: 0.2228 - val_acc: 0.9007\n",
      "Epoch 4/10\n",
      "86965/86965 [==============================] - 2s - loss: 0.1405 - acc: 0.9420 - val_loss: 0.1563 - val_acc: 0.9328\n",
      "Epoch 5/10\n",
      "86965/86965 [==============================] - 2s - loss: 0.1316 - acc: 0.9460 - val_loss: 0.1551 - val_acc: 0.9346\n",
      "Epoch 6/10\n",
      "86965/86965 [==============================] - 2s - loss: 0.1242 - acc: 0.9492 - val_loss: 0.1277 - val_acc: 0.9486\n",
      "Epoch 7/10\n",
      "86965/86965 [==============================] - 2s - loss: 0.1190 - acc: 0.9508 - val_loss: 0.1443 - val_acc: 0.9393\n",
      "Epoch 8/10\n",
      "86965/86965 [==============================] - 2s - loss: 0.1143 - acc: 0.9528 - val_loss: 0.1298 - val_acc: 0.9463\n",
      "Epoch 9/10\n",
      "86965/86965 [==============================] - 2s - loss: 0.1102 - acc: 0.9542 - val_loss: 0.1183 - val_acc: 0.9511\n",
      "Epoch 10/10\n",
      "86965/86965 [==============================] - 2s - loss: 0.1066 - acc: 0.9558 - val_loss: 0.1158 - val_acc: 0.9520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x181282486d8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=128, validation_data=(X_VALID, y_VALID), callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing VictoryNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20736/24971 [=======================>......] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_TEST, y_TEST, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the final score for VictoryNet achieved with the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[0.11928550138127307, 0.95006207200352411]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.utils import plot_model\n",
    "# plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"predictingMatchesNN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some metrics and visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y_test_predict = model.predict(X_TEST, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(y_test_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y_prob_to_class = []\n",
    "# for each_value in y_test_predict:\n",
    "#     if each_value[0] < 0.5:\n",
    "#         y_prob_to_class.append(0)\n",
    "#     else:\n",
    "#         y_prob_to_class.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import seaborn as sb\n",
    "\n",
    "# cm = confusion_matrix(y_prob_to_class, y_TEST)\n",
    "# print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sb.heatmap(cm, annot=True, cmap=\"Blues\", xticklabels=['yes', 'no'], yticklabels=['yes', 'no'])\n",
    "# plt.ylabel(\"True Label\")\n",
    "# plt.xlabel(\"Predicted Label\")\n",
    "# plt.title(\"Confusion matrix for KerasNN\")\n",
    "# plt.figtext(x=0.4, y=-0.02, s = \"figure 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(classification_report(y_prob_to_class, y_TEST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_acc = pd.read_csv(\"training_acc.csv\")\n",
    "# train_loss = pd.read_csv(\"training_loss.csv\")\n",
    "# valid_acc = pd.read_csv(\"valid_acc.csv\")\n",
    "# valid_loss = pd.read_csv(\"valid_loss.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_acc.drop([\"Wall time\", \"Step\"], axis=1, inplace=True)\n",
    "# train_loss.drop([\"Wall time\", \"Step\"], axis=1, inplace=True)\n",
    "# valid_acc.drop([\"Wall time\", \"Step\"], axis=1, inplace=True)\n",
    "# valid_loss.drop([\"Wall time\", \"Step\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(train_acc)\n",
    "# print(train_loss)\n",
    "# print(valid_acc)\n",
    "# print(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_acc.columns = [\"Training Accuracy\"]\n",
    "# ax = train_acc.plot()\n",
    "# train_loss.plot(ax=ax)\n",
    "# plt.title(\"Loss and Accuracy for training data\")\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.figtext(x=0.47, y=-0.02, s = \"figure 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# valid_acc.columns = [\"Validation Accuracy\"]\n",
    "# axs = valid_acc.plot()\n",
    "# valid_loss.plot(ax=axs)\n",
    "# plt.title(\"Loss and Accuracy for Validation data\")\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.figtext(x=0.47, y=-0.02, s = \"figure 6\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
